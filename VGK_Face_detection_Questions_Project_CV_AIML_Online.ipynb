{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Multi face detection - Questions - Project - CV - AIML Online.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5m4K1PBWaKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ecf1145-169a-4895-9cf8-76042d0d013e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCyy1_StWmua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9420a7b-c476-42a2-ac2c-217fa26a4c2a"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTeYxxCSWrmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9ce961da-5676-49fc-e18f-53531878d48b"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3131, done.\u001b[K\n",
            "remote: Counting objects: 100% (3131/3131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2699/2699), done.\u001b[K\n",
            "remote: Total 3131 (delta 602), reused 1795 (delta 377), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3131/3131), 260.57 MiB | 40.56 MiB/s, done.\n",
            "Resolving deltas: 100% (602/602), done.\n",
            "Checking out files: 100% (2990/2990), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj2zU1ZTWvPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzENBPNiWxEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "e8d00e31-a446-46f2-b5df-38d652b875fa"
      },
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (6.2.2)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.15)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /tensorflow-2.1.0/python3.6 (from Matplotlib>=2.1->object-detection==0.1) (1.18.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from kiwisolver>=1.0.1->Matplotlib>=2.1->object-detection==0.1) (45.2.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1017522 sha256=4dd280d84c93c93e138bc4c59ff49eb609d6ea62533cb25947c03e74ba467835\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-__pt8rfn/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDh7hZRIW2-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeYvBRwlW5ox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91dba871-f15e-475f-8e1c-748a1807e5a8"
      },
      "source": [
        "! pip install tensorflow-object-detection-api"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-object-detection-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/11/7f6d3c5c4b603cc40b2813059779afb641bd5eb68045c62ca520bfce0359/tensorflow_object_detection_api-0.1.1.tar.gz (577kB)\n",
            "\r\u001b[K     |▋                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 583kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (6.2.2)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (3.1.3)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (0.29.15)\n",
            "Requirement already satisfied: Protobuf in /tensorflow-2.1.0/python3.6 (from tensorflow-object-detection-api) (3.11.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-2.1.0/python3.6 (from tensorflow-object-detection-api) (2.1.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
            "Requirement already satisfied: wheel in /tensorflow-2.1.0/python3.6 (from tensorflow-object-detection-api) (0.34.2)\n",
            "Collecting twine\n",
            "  Downloading https://files.pythonhosted.org/packages/99/94/08b3b933c611416dad89c8abcc94a6d6c29e8609987235b6e7f10b42de82/twine-3.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /tensorflow-2.1.0/python3.6 (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.18.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from Protobuf->tensorflow-object-detection-api) (45.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /tensorflow-2.1.0/python3.6 (from Protobuf->tensorflow-object-detection-api) (1.14.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (4.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (4.6.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (7.5.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (2.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.27.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow->tensorflow-object-detection-api) (3.1.0)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from twine->tensorflow-object-detection-api) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.6/dist-packages (from twine->tensorflow-object-detection-api) (4.28.1)\n",
            "Collecting keyring>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/28/40/2bed013b87d6d2bf4104db67bab7c8c5b5f88ff68b383dc967b6019ee9e5/keyring-21.1.0-py2.py3-none-any.whl\n",
            "Collecting pkginfo>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/d5/451b913307b478c49eb29084916639dc53a88489b993530fed0a66bab8b9/pkginfo-1.5.0.1-py2.py3-none-any.whl\n",
            "Collecting readme-renderer>=21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/7e/d1aae793900f36b097cbfcc5e70eef82b5b56423a6c52a36dce51fedd8f0/readme_renderer-24.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20 in /tensorflow-2.1.0/python3.6 (from twine->tensorflow-object-detection-api) (2.22.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.4)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (4.5.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (2.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (4.6.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (1.0.18)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (5.0.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.8.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (1.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (0.4.1)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras-applications>=1.0.8->tensorflow->tensorflow-object-detection-api) (2.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->twine->tensorflow-object-detection-api) (2.2.0)\n",
            "Collecting SecretStorage>=3; sys_platform == \"linux\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/50/8a02cad020e949e6d7105f5f4530d41e3febcaa5b73f8f2148aacb3aeba5/SecretStorage-3.1.2-py3-none-any.whl\n",
            "Collecting jeepney>=0.4.2; sys_platform == \"linux\"\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/35/7e580cfed452e3b8c3cca44290adc54b8b5a5b8e37f89da5d24b09318be8/jeepney-0.4.2-py3-none-any.whl\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.15.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.20->twine->tensorflow-object-detection-api) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.20->twine->tensorflow-object-detection-api) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.20->twine->tensorflow-object-detection-api) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.20->twine->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (17.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.1.8)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->tensorflow-object-detection-api) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (1.3.0)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow->tensorflow-object-detection-api) (3.1.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->SecretStorage>=3; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (2.19)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-cp36-none-any.whl size=844515 sha256=651d1a6dde67c68f60cc0406cc2e0a7ea63f591fc8b68066bd575a8e7bd2c168\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/54/d0/cfca11930c4b2025d40dede77059094070a67cc3e7bd3b285f\n",
            "Successfully built tensorflow-object-detection-api\n",
            "Installing collected packages: requests-toolbelt, cryptography, jeepney, SecretStorage, keyring, pkginfo, readme-renderer, twine, tensorflow-object-detection-api\n",
            "Successfully installed SecretStorage-3.1.2 cryptography-2.8 jeepney-0.4.2 keyring-21.1.0 pkginfo-1.5.0.1 readme-renderer-24.0 requests-toolbelt-0.9.1 tensorflow-object-detection-api-0.1.1 twine-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfUidn1KW9sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cryz2OfXAUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tensorflow = tensorflow.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tensorflow.gfile = tensorflow.io.gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VvWl3ebqzCc1"
      },
      "source": [
        "# Instructions\n",
        "- Some parts of the code are already done for you\n",
        "- You need to execute all the cells\n",
        "- You need to add the code where ever you see `\"#### Add your code here ####\"`\n",
        "- Marks are mentioned along with the cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NgR0j5310qqC"
      },
      "source": [
        "# Face detection\n",
        "Task is to predict the boundaries(mask) around the face in a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aa0jyJzw091I"
      },
      "source": [
        "## Dataset\n",
        "Faces in images marked with bounding boxes. Have around 500 images with around 1100 faces manually tagged via bounding box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CjRTlPkp1LC2"
      },
      "source": [
        "### Mount Google drive if you are using google colab\n",
        "- We recommend using Google Colab as you can face memory issues and longer runtimes while running on local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBWMoTJ9cf3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23776629-8916-4066-8e1b-35ba5e5b1329"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sO9mgMmp13sI"
      },
      "source": [
        "### Change current working directory to project folder (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txKaDBOESvXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd \"/content/drive/My Drive/ComputerVisionProjectData/ObjDetection/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3srplE-FEpKa"
      },
      "source": [
        "### Load the \"images.npy\" file (4 marks)\n",
        "- This file contains images with details of bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MqFE_tZDf0sM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "data = np.load('/content/drive/My Drive/ComputerVisionProjectData/ObjDetection/images.npy', allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bspRpJW_UzTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6d05289-574b-40a5-ce87-8ad1c7a884f6"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_SMP8zliFT7R"
      },
      "source": [
        "### Check one sample from the loaded \"images.npy\" file  (4 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UdvlItx5LOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(data[0][0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m94G4p3CE5Cj"
      },
      "source": [
        "### Set image dimensions   (2 marks)\n",
        "- Initialize image height, image width with value: 224 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuZmtOASevDo",
        "colab": {}
      },
      "source": [
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wY6FEsCjG47s"
      },
      "source": [
        "### Create features and labels\n",
        "- Here feature is the image\n",
        "- The label is the mask\n",
        "- Images will be stored in \"X_train\" array\n",
        "- Masks will be stored in \"masks\" array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjCT9EVTgAvr",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "X_train = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "for index in range(data.shape[0]):\n",
        "    img = data[index][0]\n",
        "    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
        "    try:\n",
        "      img = img[:, :, :3]\n",
        "    except:\n",
        "      continue\n",
        "    X_train[index] = preprocess_input(np.array(img, dtype=np.float32))\n",
        "    for i in data[index][1]:\n",
        "        x1 = int(i[\"points\"][0]['x'] * IMAGE_WIDTH)\n",
        "        x2 = int(i[\"points\"][1]['x'] * IMAGE_WIDTH)\n",
        "        y1 = int(i[\"points\"][0]['y'] * IMAGE_HEIGHT)\n",
        "        y2 = int(i[\"points\"][1]['y'] * IMAGE_HEIGHT)\n",
        "        masks[index][y1:y2, x1:x2] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N3AYbP79bFtJ"
      },
      "source": [
        "### Print the shape of X_train and mask array  (1 mark)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3PIRaEdWIjDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f11a91a0-83ea-4844-d4f6-57d6480d347c"
      },
      "source": [
        "#### Add your code here ####\n",
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gw6uH5DxgI_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0e77aa6-22ec-4754-82c4-5fb3bc820a53"
      },
      "source": [
        "#### Add your code here ####\n",
        "masks.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 224, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R4wgkWq1bk5F"
      },
      "source": [
        "### Print a sample image and image array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qfRZjQufj0N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "97e7b2ee-72a5-4bfa-b150-5aa6c017aac2"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "n = 10\n",
        "print(X_train[n])\n",
        "pyplot.imshow(X_train[n])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " [[-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  [-0.98431373 -0.98431373 -0.98431373]\n",
            "  ...\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]\n",
            "  [-0.95294118 -0.95294118 -0.95294118]]\n",
            "\n",
            " [[-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  [-1.         -1.         -1.        ]\n",
            "  ...\n",
            "  [-0.97647059 -0.97647059 -0.97647059]\n",
            "  [-0.96862745 -0.96862745 -0.96862745]\n",
            "  [-0.96078432 -0.96078432 -0.96078432]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf340c4a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "983gGKcwlSe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c71ccde4-7592-4a60-d2d1-767447ae3119"
      },
      "source": [
        "pyplot.imshow(masks[n])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbe9af29128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0Qa1UOue9TE"
      },
      "source": [
        "## Create the model (10 marks)\n",
        "- Add MobileNet as model with below parameter values\n",
        "  - input_shape: IMAGE_HEIGHT, IMAGE_WIDTH, 3\n",
        "  - include_top: False\n",
        "  - alpha: 1.0\n",
        "  - weights: \"imagenet\"\n",
        "- Add UNET architecture layers\n",
        "  - This is the trickiest part of the project, you need to research and implement it correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BTVYOvANrUVx",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "def create_model(trainable=True):\n",
        "    model = #### Add your code here ####\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    # Add all the UNET layers here\n",
        "    #### Add your code here ####\n",
        "\n",
        "    return #### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_snZ9o0ZBAiv"
      },
      "source": [
        "### Call the create_model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TfSSP51uPoO",
        "colab": {}
      },
      "source": [
        "# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)\n",
        "model = create_model()\n",
        "\n",
        "# Print summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2spcE4TvfEZw"
      },
      "source": [
        "### Define dice coefficient function (5 marks)\n",
        "- Create a function to calculate dice coefficient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8H8aViXZuWz1",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    #### Add your code here ####\n",
        "    return #### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nkp5SDM1fIu2"
      },
      "source": [
        "### Define loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FEOVfs19KVLv",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.backend import log, epsilon\n",
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Thltv_akfOMS"
      },
      "source": [
        "### Compile the model (5 marks)\n",
        "- Complie the model using below parameters\n",
        "  - loss: use the loss function defined above\n",
        "  - optimizers: use Adam optimizer\n",
        "  - metrics: use dice_coefficient function defined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsjUoqhH5LPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "atPb8xm2qkK5",
        "colab": {}
      },
      "source": [
        "#### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VTumZyg0fuVy"
      },
      "source": [
        "### Define checkpoint and earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNlQHt8DMy7h",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
        "                             save_weights_only=True, mode=\"min\", period=1)\n",
        "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LxxbwvXEf07e"
      },
      "source": [
        "### Fit the model (5 marks)\n",
        "- Fit the model using below parameters\n",
        "  - epochs: you can decide\n",
        "  - batch_size: 1\n",
        "  - callbacks: checkpoint, reduce_lr, stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JRDJcoc5LPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guFfKsEmq58j",
        "colab": {}
      },
      "source": [
        "#### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5VtnuzlOf4uL"
      },
      "source": [
        "### Get the predicted mask for a sample image   (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_tMDiUK5LPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-CBCMysrchu",
        "colab": {}
      },
      "source": [
        "n = 10\n",
        "sample_image = X_train[n]\n",
        "\n",
        "#### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fDIetz0HgA4R"
      },
      "source": [
        "### Impose the mask on the image (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9DjyXlO5LP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MTAHGkb5xdzu",
        "colab": {}
      },
      "source": [
        "#### Add your code here ####"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}